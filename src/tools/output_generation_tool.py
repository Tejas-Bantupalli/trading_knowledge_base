from crewai.tools import BaseTool
from typing import Type, List, Dict, Any
from pydantic import BaseModel, Field
import json
import os
from datetime import datetime

class OutputGenerationInput(BaseModel):
    """Input schema for OutputGenerationTool."""
    research_session_data: str = Field(..., description="JSON string containing all research session data")
    output_type: str = Field(default="findings", description="Type of output: 'findings' or 'knowledge_graph'")

class OutputGenerationTool(BaseTool):
    name: str = "Output Generation Tool"
    description: str = (
        "Generate structured outputs including findings.md and knowledge graphs from research session data. "
        "Creates comprehensive reports and visualizes research relationships."
    )
    args_schema: Type[BaseModel] = OutputGenerationInput

    def _run(self, research_session_data: str, output_type: str = "findings") -> str:
        """Generate structured outputs from research session."""
        try:
            # Parse the research session data
            session_data = json.loads(research_session_data)
            
            if output_type == "findings":
                return self._generate_findings_md(session_data)
            elif output_type == "knowledge_graph":
                return self._generate_knowledge_graph(session_data)
            else:
                return f"Unknown output type: {output_type}"
                
        except Exception as e:
            return f"Error generating output: {str(e)}"

    def _generate_findings_md(self, session_data: Dict[str, Any]) -> str:
        """Generate findings.md file content."""
        try:
            # Extract key information from session data
            user_query = session_data.get('user_query', 'Unknown Query')
            papers = session_data.get('papers', [])
            summaries = session_data.get('summaries', [])
            answers = session_data.get('answers', [])
            research_context = session_data.get('research_context', '')
            
            # Create the findings.md content
            findings_content = f"""# Research Findings Report

## Executive Summary
**Query**: {user_query}
**Research Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Research Context**: {research_context}

## Key Findings

### 1. Research Overview
This report presents findings from a comprehensive analysis of quantitative finance research papers related to: **{user_query}**

### 2. Papers Analyzed
"""
            
            # Add paper summaries
            for i, paper in enumerate(papers, 1):
                findings_content += f"""
#### Paper {i}: {paper.get('title', 'Unknown Title')}
- **Authors**: {paper.get('authors', 'Unknown')}
- **ArXiv ID**: {paper.get('arxiv_id', 'Unknown')}
- **URL**: {paper.get('url', 'N/A')}
- **Relevance Score**: {paper.get('similarity_score', 'N/A')}

**Summary**: {summaries[i-1] if i <= len(summaries) else 'Summary not available'}

---
"""

            # Add query answers
            if answers:
                findings_content += """
### 3. Query Analysis
"""
                for i, answer in enumerate(answers, 1):
                    findings_content += f"""
#### Answer {i}
{answer}

---
"""

            # Add conclusions
            findings_content += """
### 4. Conclusions and Recommendations

Based on the analysis of the research papers, the following conclusions can be drawn:

1. **Key Insights**: [To be filled based on analysis]
2. **Limitations**: [To be filled based on analysis]
3. **Future Research Directions**: [To be filled based on analysis]
4. **Practical Implications**: [To be filled based on analysis]

### 5. Methodology Notes

This research was conducted using:
- Vector similarity search for paper retrieval
- AI-powered summarization and analysis
- Multi-agent collaboration for comprehensive coverage
- Critical review for accuracy validation

---
*Report generated by FinResearchProject Crew*
"""

            # Write to file
            output_path = "findings.md"
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(findings_content)
            
            return json.dumps({
                "output_type": "findings",
                "file_path": output_path,
                "content_length": len(findings_content),
                "status": "success"
            }, indent=2)
            
        except Exception as e:
            return f"Error generating findings.md: {str(e)}"

    def _generate_knowledge_graph(self, session_data: Dict[str, Any]) -> str:
        """Generate knowledge graph structure."""
        try:
            # Extract entities and relationships
            papers = session_data.get('papers', [])
            user_query = session_data.get('user_query', 'Unknown Query')
            
            # Create knowledge graph structure
            knowledge_graph = {
                "nodes": [],
                "edges": [],
                "metadata": {
                    "query": user_query,
                    "generated_at": datetime.now().isoformat(),
                    "total_papers": len(papers)
                }
            }
            
            # Add query node
            knowledge_graph["nodes"].append({
                "id": "user_query",
                "type": "query",
                "label": user_query,
                "properties": {
                    "timestamp": datetime.now().isoformat()
                }
            })
            
            # Add paper nodes and relationships
            for i, paper in enumerate(papers):
                paper_id = f"paper_{i+1}"
                
                # Add paper node
                knowledge_graph["nodes"].append({
                    "id": paper_id,
                    "type": "paper",
                    "label": paper.get('title', 'Unknown Title'),
                    "properties": {
                        "arxiv_id": paper.get('arxiv_id', 'Unknown'),
                        "authors": paper.get('authors', 'Unknown'),
                        "similarity_score": paper.get('similarity_score', 0),
                        "url": paper.get('url', 'N/A')
                    }
                })
                
                # Add relationship from query to paper
                knowledge_graph["edges"].append({
                    "source": "user_query",
                    "target": paper_id,
                    "type": "sourced_from",
                    "properties": {
                        "relevance_score": paper.get('similarity_score', 0)
                    }
                })
                
                # Add relationships between papers (if multiple)
                if i > 0:
                    knowledge_graph["edges"].append({
                        "source": f"paper_{i}",
                        "target": paper_id,
                        "type": "related_to",
                        "properties": {
                            "relationship": "co-research"
                        }
                    })
            
            # Write knowledge graph to file
            output_path = "knowledge_graph.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(knowledge_graph, f, indent=2)
            
            return json.dumps({
                "output_type": "knowledge_graph",
                "file_path": output_path,
                "nodes_count": len(knowledge_graph["nodes"]),
                "edges_count": len(knowledge_graph["edges"]),
                "status": "success"
            }, indent=2)
            
        except Exception as e:
            return f"Error generating knowledge graph: {str(e)}" 